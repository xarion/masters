% !TEX root = ../thesis.tex
\iffalse
Taken from http://www.ldeo.columbia.edu/~martins/sen_sem/thesis_org.html
Methods
What belongs in the "methods" section of a scientific paper?
    Information to allow the reader to assess the believability of your results.
    Information needed by another researcher to replicate your experiment.
    Description of your materials, procedure, theory.
    Calculations, technique, procedure, equipment, and calibration plots. 
    Limitations, assumptions, and range of validity.
    Desciption of your analystical methods, including reference to any specialized statistical software. 
The methods section should answering the following questions and caveats: 
    Could one accurately replicate the study (for example, all of the optional and adjustable parameters on any sensors or instruments that were used to acquire the data)?
    Could another researcher accurately find and reoccupy the sampling stations or track lines?
    Is there enough information provided about any instruments used so that a functionally equivalent instrument could be used to repeat the experiment?
    If the data are in the public domain, could another researcher lay his or her hands on the identical data set?
    Could one replicate any laboratory analyses that were used? 
    Could one replicate any statistical analyses?
    Could another researcher approximately replicate the key algorithms of any computer software?
Citations in this section should be limited to data sources and references of where to find more complete descriptions of procedures.
Do not include descriptions of results. 
\fi
\iffalse
We need to be talking about these.
    Quantization
        8-bit (known to work in mobile, we will test it in the very end)
        n-bit (not possible with Tensorflow)
    Pruning,
        by weight (done)
        by neuron activations (done)
        by Fisher Information Metric (skipped because hard to implement)
    Different Types of Operators,
        ef-operation (http://arxiv.org/abs/1702.02676) (not possible with Tensorflow)
        separable convolutions (done)
    Factorization,
        by SVD (done)
        weight sharing (not possible with Tensorflow)
        non-negative matrix factorization (not good in theory)
    Different Structures,
        bottleneck blocks (reported)
        inception blocks (to be reported)
        1D convolutions (done)
        spiking neural network (not possible)
    Improving Network Efficiency
        Residual Connections
        Batch Normalization
\fi



















